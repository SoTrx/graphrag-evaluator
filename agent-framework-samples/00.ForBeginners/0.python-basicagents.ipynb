{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2012ea09",
   "metadata": {},
   "source": [
    "# ü§ñ Basic Agents with Microsoft Agent Framework (Python)\n",
    "\n",
    "## üìã What You'll Learn\n",
    "\n",
    "This notebook shows you how to create AI agents using the Microsoft Agent Framework. You'll see three different ways to create agents and how to have conversations with them.\n",
    "\n",
    "**What's Inside:**\n",
    "- üèóÔ∏è **Three Agent Creation Methods**: GitHub Models, Azure OpenAI, and Azure AI Foundry\n",
    "- üõ†Ô∏è **Tool Integration**: Adding custom functions agents can call\n",
    "- üí¨ **Conversation Management**: Single-turn and multi-turn conversations\n",
    "- üîÑ **Streaming Responses**: Real-time response display\n",
    "\n",
    "## ‚öôÔ∏è Setup Requirements\n",
    "\n",
    "### 1. **Docker & Dev Container**\n",
    "- Install Docker on your machine\n",
    "- Open this project in the dev container (VS Code will prompt you)\n",
    "\n",
    "### 2. **Workspace Configuration**\n",
    "- Open the workspace: `File > Open Workspace from File` ‚Üí select `workspace.code-workspace`\n",
    "- This sets up the correct Python environment for each project folder\n",
    "\n",
    "### 3. **Environment Variables**\n",
    "1. Copy `.env.example` to `.env` in the `agent-framework-samples` folder:\n",
    "   ```bash\n",
    "   cp .env.example .env\n",
    "   ```\n",
    "2. Fill in your credentials:\n",
    "   ```env\n",
    "   # For GitHub Models (Option 1)\n",
    "   GITHUB_TOKEN=your_github_token\n",
    "   GITHUB_ENDPOINT=https://models.inference.ai.azure.com\n",
    "   GITHUB_MODEL_ID=gpt-4o-mini\n",
    "   \n",
    "   # For Azure OpenAI (Option 2)\n",
    "   AZURE_OPENAI_ENDPOINT=your_endpoint\n",
    "   AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=your_deployment\n",
    "   \n",
    "   # For Azure AI Foundry (Option 3)\n",
    "   AZURE_AI_PROJECT_ENDPOINT=your_project_endpoint\n",
    "   AZURE_AI_MODEL_DEPLOYMENT_NAME=your_model\n",
    "   \n",
    "   # For Local Ollama (Option 4)\n",
    "   OLLAMA_ENDPOINT=http://localhost:11434/v1\n",
    "   OLLAMA_DEPLOYMENT_NAME=llama3\n",
    "   ```\n",
    "\n",
    "## üöÄ What You'll Build\n",
    "\n",
    "Below you'll find code samples demonstrating:\n",
    "\n",
    "1. **Tool Definition**: A simple function that picks random travel destinations\n",
    "2. **Agent Configuration**: Instructions that define agent behavior\n",
    "3. **Three Creation Patterns**:\n",
    "   - **Option 1**: GitHub Models (simplest, uses OpenAI-compatible API)\n",
    "   - **Option 2**: Azure OpenAI (local agent, no persistence)\n",
    "   - **Option 3**: Azure AI Foundry (persistent agent in the cloud)\n",
    "4. **Conversation Examples**: Single-turn and multi-turn conversations with streaming\n",
    "\n",
    "Let's start building! üåü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0df8a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os                     \n",
    "from random import randint    \n",
    "\n",
    "from dotenv import load_dotenv  \n",
    "from agent_framework import ChatAgent\n",
    "from azure.identity import AzureCliCredential, DefaultAzureCredential\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6507f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üõ†Ô∏è Tool Function Design Pattern\n",
    "def get_random_destination() -> str:\n",
    "    \"\"\"Get a random vacation destination using Repository Pattern.\n",
    "    \n",
    "    Returns:\n",
    "        str: A randomly selected destination following consistent format\n",
    "    \"\"\"\n",
    "    destinations = [\n",
    "        \"Barcelona, Spain\",      \n",
    "        \"Paris, France\",         \n",
    "        \"Berlin, Germany\",       \n",
    "        \"Tokyo, Japan\",          \n",
    "        \"Sydney, Australia\",     \n",
    "        \"New York, USA\",         \n",
    "        \"Cairo, Egypt\",          \n",
    "        \"Cape Town, South Africa\", \n",
    "        \"Rio de Janeiro, Brazil\",  \n",
    "        \"Bali, Indonesia\"          \n",
    "    ]\n",
    "    \n",
    "    return destinations[randint(0, len(destinations) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e09a774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_NAME =\"TravelAgent\"\n",
    "\n",
    "AGENT_INSTRUCTIONS = \"\"\"You are a helpful AI Agent that can help plan vacations for customers.\n",
    "\n",
    "Important: When users specify a destination, always plan for that location. Only suggest random destinations when the user hasn't specified a preference.\n",
    "\n",
    "When the conversation begins, introduce yourself with this message:\n",
    "\"Hello! I'm your TravelAgent assistant. I can help plan vacations and suggest interesting destinations for you. Here are some things you can ask me:\n",
    "1. Plan a day trip to a specific location\n",
    "2. Suggest a random vacation destination\n",
    "3. Find destinations with specific features (beaches, mountains, historical sites, etc.)\n",
    "4. Plan an alternative trip if you don't like my first suggestion\n",
    "\n",
    "What kind of trip would you like me to help you plan today?\"\n",
    "\n",
    "Always prioritize user preferences. If they mention a specific destination like \"Bali\" or \"Paris,\" focus your planning on that location rather than suggesting alternatives.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6da017ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Using GitHub Models via OpenAIChatClient\n",
    "\n",
    "chat_client = OpenAIChatClient(\n",
    "    base_url=os.environ.get(\"GITHUB_ENDPOINT\"), \n",
    "    api_key=os.environ.get(\"GITHUB_TOKEN\"),\n",
    "    model_id=os.environ.get(\"GITHUB_MODEL_ID\"))\n",
    "\n",
    "chat_agent = ChatAgent(\n",
    "        name = AGENT_NAME,\n",
    "        chat_client=chat_client,\n",
    "        instructions=AGENT_INSTRUCTIONS,\n",
    "        tools=[get_random_destination]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43272ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option 2: Using Azure OpenAi client to generate a local agent\n",
    "\n",
    "chat_agent = AzureOpenAIChatClient(credential=DefaultAzureCredential()).create_agent(\n",
    "    instructions=AGENT_INSTRUCTIONS,\n",
    "    name = AGENT_NAME,\n",
    "    tools=[get_random_destination]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37f7c87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent TravelAgent created, and chat agent ready\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "#Option 3: Using persisted Azure AI Foundry Agents \n",
    "\n",
    "chat_agent : ChatAgent\n",
    "credential = DefaultAzureCredential()\n",
    "project_client = AIProjectClient(endpoint=os.environ[\"AZURE_AI_PROJECT_ENDPOINT\"],credential=credential)\n",
    "\n",
    "try:\n",
    "    # Create an agent that will persist\n",
    "    created_agent = await project_client.agents.create_agent(\n",
    "        model=os.environ[\"AZURE_AI_MODEL_DEPLOYMENT_NAME\"], \n",
    "        name=AGENT_NAME,\n",
    "        instructions=AGENT_INSTRUCTIONS\n",
    "    )\n",
    "    \n",
    "    chat_agent = ChatAgent(\n",
    "        chat_client=AzureAIAgentClient(project_client=project_client, agent_id=created_agent.id),\n",
    "        tools=[get_random_destination])\n",
    "    \n",
    "    print(f\"Agent {created_agent.name} created, and chat agent ready\")\n",
    "    \n",
    "finally:\n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95757d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_client = OpenAIChatClient(base_url= os.environ.get(\"OLLAMA_ENDPOINT\"),api_key=\"nokey\", model_id=os.environ.get(\"OLLAMA_DEPLOYMENT_NAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "772e9481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel plan:\n",
      "Great! I‚Äôd love to help you plan a day trip. Could you please tell me which location, city, or area you‚Äôd like to visit? Or would you like me to suggest a random destination for your day trip?\n"
     ]
    }
   ],
   "source": [
    "# Creating a new conversation instance with the agent storing the history of messages for this specific run\n",
    "thread = chat_agent.get_new_thread()\n",
    "\n",
    "response1 = await chat_agent.run(\"Plan me a day trip\",thread= thread)\n",
    "\n",
    "last_message = response1.messages[-1]\n",
    "text_content = last_message.contents[0].text\n",
    "print(\"Travel plan:\")\n",
    "print(text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d3fe00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-27 17:20:51 - /workspaces/graphrag-evaluator/agent-framework-samples/.venv/lib/python3.12/site-packages/agent_framework/_clients.py:704 - WARNING] When conversation_id is set, store must be True for service-managed threads. Automatically setting store=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Since you haven‚Äôt specified a destination yet, would you like me to suggest a random vacation destination, or do you have a location, theme, or type of activity in mind (beaches, mountains, historical sites, etc.)? Let me know your preferences so I can tailor your vacation plan!"
     ]
    }
   ],
   "source": [
    "# Adding a new user message to change the plan, on top of the past first round of conversation\n",
    "# Getting the answers as a stream : \n",
    "\n",
    "async for chunk in chat_agent.run_stream(\"I don't like that destination. Plan me another vacation.\", thread=thread):\n",
    "    if chunk.text:\n",
    "        print(chunk.text, end=\"\", flush=True)  # üìù Display response as it generates\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-framework-samples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
